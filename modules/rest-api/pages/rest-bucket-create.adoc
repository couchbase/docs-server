= Creating and Editing Buckets
:page-topic-type: reference

[abstract]
Buckets are created and edited with the `POST /pools/default/buckets` HTTP method and URI.

[#http-methods-and-uris]
== HTTP Methods and URIs

----
POST /pools/default/buckets

POST /pools/default/buckets/<bucketName>
----

[#description]
== Description

These respectively create a new bucket and edit an existing bucket.
The bucket can be of any type: Couchbase, Ephemeral, or Memcached.
On creation, a bucket must be assigned a name that is unique among buckets defined on the cluster: this name cannot subsequently be changed.
Names cannot be longer than 100 bytes (which is to say, characters).

A maximum of 30 buckets can be created on a single cluster.

[#curl-syntax]
== Curl Syntax

Note that all floats and integers in the following are _non-negative_ only.

----
curl -X POST -u <administrator>:<password>
  http://<ip-address-or-hostname>:<port>/pools/default/buckets
  -d name=<bucketName>
  -d bucketType=[ couchbase | ephemeral | memcached ]
  -d ramQuotaMB=<integer>
  -d evictionPolicy=[
          [ valueOnly | full ] |
          [ noEviction | nruEviction ]
        ]
  -d durabilityMinLevel=[
          [ none | majority | majorityAndPersistActive | persistToMajority ] |
          [ none | majority ]
        ]
  -d threadsNumber=[ 3 | 8 ]
  -d replicaNumber=[ 1 | 2 | 3 ]
  -d compressionMode=[ off | passive | active ]
  -d maxTTL=<integer>
  -d replicaIndex=[ 0 | 1 ]
  -d conflictResolutionType=[ seqno | lww ]
  -d autoCompactionDefined=[ true | false ]
  -d parallelDBAndViewCompaction=[ true | false ]
  -d databaseFragmentationThreshold[percentage]=<integer>
  -d databaseFragmentationThreshold[size]=<integer>
  -d viewFragmentationThreshold[percentage]=<integer>
  -d viewFragmentationThreshold[size]=<integer>
  -d indexCompactionMode=[ circular | append ]
  -d purgeInterval=[ <float> | <integer> ]
  -d allowedTimePeriod[abortOutside]=true
  -d allowedTimePeriod[toMinute]=<integer>
  -d allowedTimePeriod[toHour]=<integer>
  -d allowedTimePeriod[fromMinute]=<integer>
  -d allowedTimePeriod[fromHour]=<integer>
  -d flushEnabled=[ 0 | 1 ]
----

The parameters are as follows:

* `name`.
A name for a bucket that is to be created.
The name must be unique among the bucket-names defined for the cluster, and cannot be longer than 100 characters.
Acceptable characters are `A-Z`, `a-z`, and `0-9`.
Additionally, the _underscore_, _period_, _dash_, and _percent_ characters can be used.
+
The name parameter _must_ be specified, if a bucket is being created.
If it is not, or if the intended name is improperly designed, an error-notification is returned.
For example: : `{"name":"Bucket name needs to be specified"}`.
Note that a bucket-name _cannot_ be changed after bucket-creation.
Therefore, if this parameter is specified in an attempt to edit the bucket-configuration, it is ignored.
To edit the configuration of an existing bucket, the bucket-name must be specified as the `<bucketName>` path-parameter; as indicated above, in xref:rest-api:rest-bucket-create.adoc#http-methods-and-uris[HTTP Methods and URIs].

* `bucketType`.
The _type_ of the bucket, which can be `couchbase` (which is the default), `ephemeral`, or `memcached`.
For a detailed explanation of bucket types, see xref:learn:buckets-memory-and-storage/buckets.adoc[Buckets].
+
If an invalid bucket type is specified, the error-notification `{"bucketType":"invalid bucket type"}` is returned.
+
This parameter _cannot_ be modified, following bucket-creation.
Therefore, if it is specified in an attempt to edit the bucket-configuration, the parameter is ignored.

* `ramQuota`.
The amount of memory to be allocated to the bucket, per node, in megabytes.
The minimum amount is 100 MB.
The maximum amount is the total Data Service memory quota configured per node, minus the amount already assigned to other buckets.
For information on per node memory configuration, see the page for xref:manage:manage-settings/general-settings.adoc[General] Settings.
+
A value for `ramQuota` _must_ be specified: the value _can_ be modified, following bucket-creation.
+
An incorrect memory-specification returns a notification such as `{"ramQuotaMB":"RAM quota cannot be less than 100 MB"}`.

* `evictionPolicy`.
The _ejection policy_ to be assigned to and used by the bucket.
(Note that _eviction_ is, in the current release, referred to as _ejection_; and this revised naming will continue to be used in future releases.)
Policy-assignment depends on bucket type.
For a _Couchbase_ bucket, the policy can be `valueOnly` (which is the default) or `full`.
For an _Ephemeral_ bucket, the policy can be `noEviction` (which is the default) or `nruEviction`.
No policy can be assigned to a _Memcached_ bucket.
+
This value _can_ be modified, following bucket-creation.
If such modification occurs, the bucket is restarted with the new setting: this may cause inaccessibility of data, during the bucket's warm-up period.
+
Incorrect specification of an ejection policy returns an error-notification, such as `{"evictionPolicy":"Eviction policy must be either 'valueOnly' or 'fullEviction' for couchbase buckets"}`.
+
For information on ejection policies, see xref:learn:buckets-memory-and-storage/buckets.adoc#bucket-types[Bucket Types].
For general information on memory management in the context of ejection, see xref:learn:buckets-memory-and-storage/memory.adoc#ejection[Ejection].

* `durabilityMinLevel`.
A _durability level_ to be assigned to the bucket, as the minimum level at which all writes to the bucket must occur.
Level-assignment depends on bucket type.
For a _Couchbase_ bucket, the level can be `none`, `majority`, `majorityAndPersistActive`, or `persistToMajority`.
For an _Ephemeral_ bucket, the level can be `none` or `majority`.
No level can be assigned to a _Memcached_ bucket.
+
This parameter _can_ be modified, following bucket-creation.
+
For information on durability and levels, see xref:learn:data/durability.adoc[Durability].

* `threadsNumber`.
The _priority_ for the bucket, as described in xref:manage:manage-buckets/create-bucket.adoc#bucket-priority[Create a Bucket].
Priority can be established as either _Low_ or _High_.
To establish priority as _Low_ (which is the default), the value of `threadsNumber` must be `3`.
To establish priority as _High_, the value must be `8`.
If any other value is used, the value is ignored; and the bucket's priority remains low.
+
If this parameter is incorrectly specified, an error-notification such as the following is returned: `{"threadsNumber":"The number of threads must be an integer between 2 and 8"}`.
(Note that, as indicated above, all values other than `3` and `8` are ignored.)
+
This parameter _can_ be modified, following bucket-creation.
If such modification occurs, the bucket is restarted with the new setting: this may cause inaccessibility of data, during the bucket's warm-up period.

* `replicaNumber`.
The number of _replicas_ for the bucket.
For information on replicas and replication, see xref:learn:clusters-and-availability/intra-cluster-replication.adoc[Intra-Cluster Replication] and xref:learn:buckets-memory-and-storage/vBuckets.adoc[vBuckets].
The possible values are `0` (which _disables_ replication, and therefore ensures that no replicas will be maintained), `1` (which is the default), `2`, and `3`.
If a number greater than `3` is specified, the following error-notification is returned: `{"replicaNumber":"Replica number larger than 3 is not supported."}`.
+
If more replicas are requested than can be assigned to the cluster, due to an insufficient number of nodes, no notification is returned. Instead, the maximum possible number of replicas is created: additional replicas will be added subsequently, if more nodes become available.
+
This parameter _can_ be modified, following bucket-creation.
Such modification may require a rebalance: for information, see xref:learn:clusters-and-availability/rebalance.adoc[Rebalance].

* `compressionMode`.
The _compression mode_ for the bucket.
The possible values are `off`, `passive` (which is the default), and `active`.
If the value is incorrectly specified, the following error-notification is returned: `{"compressionMode":"compressionMode can be set to 'off', 'passive' or 'active'"}`.
+
This parameter _can_ be modified, following bucket-creation.
+
For information on compression and compression modes, see xref:learn:buckets-memory-and-storage/compression.adoc[Compression].

* `maxTTL`.
The bucket's _Time To Live_ (TTL); which imposes a maximum lifespan on items within a bucket, and thus ensures the expiration of such items, once the specified period is complete.
The value must be an integer, which specifies a number of seconds.
The maximum value is MAX32INT (`2147483648` seconds, or `68.096` years).
The default value is `0`, which disables TTL for the bucket.
Specifying any positive value up to MAX32INT enables TTL for the bucket.
Specifying an incorrect value returns an error-notification such as the following: `{"maxTTL":"Max TTL must be an integer between 0 and 2147483647"}`.
+
This parameter _can_ be modified, following bucket-creation.
+
For information on TTL, see xref:learn:buckets-memory-and-storage/expiration.adoc[Expiration].

* `replicaIndex`.
Specifies whether _View Indexes_ are to be replicated.
The value can be either `0` (which is the default), specifying that they are _not_ to be replicated; or `1`, specifying that they _are_ to be replicated.
Specifying any other value returns an error-notification such as the following: `{"replicaIndex":"replicaIndex can only be 1 or 0"}`.
+
This option is valid for Couchbase buckets only.
Note that there may be, at most, _one_ replica view index.

* `conflictResolutionType`.
Specifies the _conflict resolution type_ for the bucket.
The value can be `seqno` (which is the default), specifying sequence-number based resolution; or `lww` (_last write wins_), specifying timestamp-based resolution.
+
The value _cannot_ be changed after bucket-creation.
Therefore, if the parameter is specified in an attempt to edit the bucket-configuration, it is ignored.
+
For information on conflict resolution, see: xref:learn:clusters-and-availability/xdcr-conflict-resolution.adoc[XDCR Conflict Resolution].

* `autoCompactionDefined`.
Specifies whether the default _auto-compaction_ settings are to be modified for this bucket.
The value specified can be either `true` or `false` (which is the default).
If the value is `false`, any parameter-values specified in order to modify the default auto-compaction settings are ignored.
If the value is incorrectly specified, an error-notification such as the following is returned: `{"autoCompactionDefined":"autoCompactionDefined is invalid"}`.
+
Note that if `autoCompactionDefined` is specified as `true`, `parallelDBAndViewCompaction` must also be defined.
Otherwise, an error-notification such as the following is returned: `{"parallelDBAndViewCompaction":"parallelDBAndViewCompaction is missing"}`.
+
Auto-compaction settings are unnecessary for _memory-optimized_ indexes.
For information on index storage, see xref:learn:services-and-indexes/indexes/storage-modes.adoc[Storage Settings].
+
For further information on auto-compaction settings, see xref:manage:manage-settings/configure-compact-settings.adoc[Auto-Compaction].

* `parallelDBAndViewCompaction`.
Specifies whether compaction should occur to documents and view indexes in parallel.
This is a _global_ setting, which therefore affects _all_ buckets on the cluster.
The value can either be `true` or `false` (which is the default).
If the value is incorrectly specified, the following error-notification is returned: `{"parallelDBAndViewCompaction":"parallelDBAndViewCompaction is invalid"}`.
+
This parameter-value is ignored if `autoCompactionDefined` is `false` (which is its default value).

* `databaseFragmentationThreshold[percentage]`.
Specifies, as a percentage, the level of database fragmentation that must be reached for data compaction to be automatically triggered.
The assigned value must be an integer.
The default value is `"undefined"`.
+
If a value for `databaseFragmentationThreshold[size]` is also specified, data compaction is automatically triggered as soon as the threshold specified by one parameter or the other is reached.
+
If this parameter is incorrectly specified, an error-notification such as the following is returned: `"databaseFragmentationThreshold[percentage]":"database fragmentation must be an integer"`.
+
This parameter is ignored if `autoCompactionDefined` is `false` (which is its default value).

* `databaseFragmentationThreshold[size]`.
Specifies, as a size in megabytes, the level of database fragmentation that must be reached for data compaction to be automatically triggered.
The assigned value must be an integer.
The default value is `"undefined"`.
+
If a value for `databaseFragmentationThreshold[threshold]` is also specified, data compaction is automatically triggered as soon as the threshold specified by one parameter or the other is reached.
+
If this parameter is incorrectly specified, an error-notification such as the following is returned: `"databaseFragmentationThreshold[size]":"database fragmentation must be an integer"`.
+
This parameter is ignored if `autoCompactionDefined` is `false` (which is its default value).

* `viewFragmentationThreshold[percentage]`.
Specifies, as a percentage, the level of View fragmentation that must be reached for View compaction to be automatically triggered.
The assigned value must be an integer.
The default value is `"undefined"`.
+
If a value for `viewFragmentationThreshold[size]` is also specified, View compaction is automatically triggered as soon as the threshold specified by one parameter or the other is reached.
+
If this parameter is incorrectly specified, an error-notification such as the following is returned: `"viewFragmentationThreshold[percentage]":"view fragmentation must be an integer"`.
+
This parameter is ignored if `autoCompactionDefined` is `false` (which is its default value).

* `viewFragmentationThreshold[size]`.
Specifies, as a size in megabytes, the level of View fragmentation that must be reached for View compaction to be automatically triggered.
The assigned value must be an integer.
The default value is `"undefined"`.
+
If a value for `viewFragmentationThreshold[threshold]` is also specified, View compaction is automatically triggered as soon as the threshold specified by one parameter or the other is reached.
+
If this parameter is incorrectly specified, an error-notification such as the following is returned: `"viewFragmentationThreshold[size]":"view fragmentation size must be an integer"`.
+
This parameter is ignored if `autoCompactionDefined` is `false` (which is its default value).

* `indexCompactionMode`.
Specifies the write-strategy for index compaction.
The value can either be `circular` (which is the default) or `append`.
For information on index compaction, see xref:learn:services-and-indexes/indexes/storage-modes.adoc#standard-index-storage.
+
This parameter is only valid for Couchbase Server Community Edition: it is ignored if specified on Enterprise Edition.
+
This parameter is ignored if `autoCompactionDefined` is `false` (which is its default value).

* `purgeInterval`.
Specifies the tombstone (or metadata) purge interval.
The value can be either an integer (indicating a number of days), or a float (indicating an interval that may be greater or less than one day, and entails a number of hours, with `0.04` indicating _one hour_).
The default value is three days.
+
If this parameter is incorrectly specified, an error-notification such as the following is returned: `{"purgeInterval":"metadata purge interval must be a number"}`.
+
For more information see xref:manage:manage-settings/configure-compact-settings.adoc#tombstone-purge-interval[Tombstone Purge Interval] and xref:learn:buckets-memory-and-storage/storage.adoc[Storage].
+
This parameter is ignored if `autoCompactionDefined` is `false` (which is its default value).

== Response

If the bucket creation was successful, HTTP response 202 (Accepted) is returned with empty content.

----
202 Accepted
----

== Response codes

If the bucket could not be created, because the parameter was missing or incorrect, HTTP response 400 returns, with a JSON payload containing the error reason.

.Create bucket error codes
[cols="1,4"]
|===
| Error codes | Description

| 202
| Accepted

| 400
a|
Bad Request JSON with errors in the form of `{"errors": {….
}}`.
Possible error messages include:

* name: Bucket with given name already exists
* ramQuotaMB: RAM Quota is too large or too small
* replicaNumber: Must be specified and must be a non-negative integer
* proxyPort: port is invalid, port is already in use

| 404
| Object Not Found
|===
