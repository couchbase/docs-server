// tag::dict[]
A `dict_compound` token filter uses a wordlist to find subwords inside an input token. 
If the token filter finds a subword inside a compound word, it turns it into a separate token. 

[source,json]
----
include::example$search/complex-search-index-payload.jsonc[tag=dict_compound_filter]
----

For example, if you had a wordlist that contained `play` and `jump`, the token filter converts `playful jumping` into two tokens: `play` and `jump`.

[plantuml,dict,svg]
....
@startuml

(playful jumping) as Start <<Input Token>>
(play) <<Output>>
(jump) <<Output>>
rectangle wordlist {
    usecase "play" as WL1
    usecase "jump" as WL2
}

Start --> (play) 
Start --> (jump)
@enduml
....
// end::dict[]

// tag::edge[]
An `edge_ngram` token filter uses a specified range to create new tokens. 
You can also choose whether to create the new token from the start or backward from the end of the input token. 

[source,json]
----
include::example$search/complex-search-index-payload.jsonc[tag=edge_ngram_filter]
----

For example, if you had a miminum of four and a maximum of five with an input token of `breweries`, the token filter creates the tokens `brew` and `brewe`.

[plantuml,edge,svg]
....
@startuml

(breweries) as Start <<Input Token>>
(brew) <<Output>>
(brewe) <<Output>>
rectangle range {
    usecase "min: 4" as R1
    usecase "max: 5" as R2
}

Start --> (brew) 
Start --> (brewe)
@enduml
....
// end::edge[]

// tag::elision[]
An `elision` token filter removes elisions from input tokens. 

[source,json]
----
include::example$search/complex-search-index-payload.jsonc[tag=elision_filter]
----

For example, if you had the `stop_fr` wordlist in an elision token filter, the token `je m'appelle John` becomes the tokens `je`, `appelle`, and `John`.

[plantuml,elision,svg]
....
@startuml

(je m'appelle John) as Start <<Input Token>>
(je) <<Output>>
(appelle) <<Output>>
(John) <<Output>>
rectangle wordlist {
    usecase "stop_fr" as WL1
}

Start --> (je) 
Start --> (appelle)
Start --> (John)
@enduml
....
// end::elision[]

// tag::keyword[]
A `keyword_marker` token filter finds keywords in an input token and turns them into tokens. 

[source,json]
----
include::example$search/complex-search-index-payload.jsonc[tag=keyword_marker_filter]
----

For example, if you had a wordlist that contained the keyword `beer`, the token `beer and breweries` becomes the token `beer`.

[plantuml,keyword,svg]
....
@startuml

(beer and breweries) as Start <<Input Token>>
(beer) <<Output>>
rectangle wordlist {
    usecase "beer" as WL1
}

Start --> (beer) 
@enduml
....
// end::keyword[]

// tag::length[]
A `length` token filter removes tokens that are shorter or longer than a set character length. 

[source,json]
----
include::example$search/complex-search-index-payload.jsonc[tag=length_filter]
----

For example, if you had a range with a minimum of two and a maximum of four, the token `beer and breweries` becomes the tokens `beer` and `and`.

[plantuml,length,svg]
....
@startuml

(beer and breweries) as Start <<Input Token>>
(beer) <<Output>>
(and) <<Output>>

Start --> (beer)
Start --> (and)
@enduml
....
// end::length[]

// tag::ngram[]
An `ngram` token filter uses a specified character length to split an input token into new tokens. 

[source,json]
----
include::example$search/complex-search-index-payload.jsonc[tag=ngram_filter]
----

For example, if you had a range with a minimum of four and a maximum of five, the token `beers` becomes the tokens `beer`, `beers`, and `eers`.

[plantuml,ngram,svg]
....
@startuml

(beers) as Start <<Input Token>>
(beer) <<Output>>
(beers) <<Output>>
(eers) <<Output>>

Start --> (beer)
Start --> (beers)
Start --> (eers) 
@enduml
....
// end::ngram[]

// tag::normalize[]
A `normalize_unicode` token filter uses a specified Unicode Normalization form to create new tokens. 

[source,json]
----
include::example$search/complex-search-index-payload.jsonc[tag=normalize_unicode_filter]
----
// end::normalize[]

// tag::shingle[]
A `shingle` token filter uses a specified character length and separator to create new tokens.

[source,json]
----
include::example$search/complex-search-index-payload.jsonc[tag=shingle_filter]
----

For example, if you use a xref:guides:search/customize-index.adoc#whitespace[whitespace tokenizer], a range with a minimum of two and a maximum of three, and a space as a separator, the token `abc def` becomes `abc`, `def`, and `abc def`.

[plantuml,shingle,svg]
....
@startuml

(abc def) as Start <<Input Token>>

(abc) <<Output>>
(def) <<Output>>
(abc def) <<Output>>

Start --> (abc)
Start --> (def)
Start --> (abc def) 
@enduml
....
// end::shingle[]

// tag::stop[]
A `stop_tokens` token filter uses a wordlist to remove specific tokens from input. 

[source,json]
----
include::example$search/complex-search-index-payload.jsonc[tag=stop_tokens_filter]
----

For example, if you have a wordlist that contains the word `and`, the token `beers and breweries` becomes `beers` and `breweries`.

[plantuml,stop,svg]
....
@startuml

(beers and breweries) as Start <<Input Token>>
(beers) <<Output>>
(breweries) <<Output>>

rectangle wordlist {
    usecase "and" as WL1
}

Start --> (beers)
Start --> (breweries)
@enduml
....
// end::stop[]

// tag::truncate[]
A `truncate_token` token filter uses a specified character length to shorten any input tokens that are too long. 

[source,json]
----
include::example$search/complex-search-index-payload.jsonc[tag=truncate_token_filter]
----

For example, if you had a `length` of four, the token `beer and breweries` becomes `beer`, `and`, and `brewe`.

[plantuml,truncate,svg]
....
@startuml

(beer and breweries) as Start <<Input Token>>
(beer) <<Output>>
(and) <<Output>>
(brewe) <<Output>>

rectangle length {
    usecase "4" as L1
}

Start --> (beer)
Start --> (and)
Start --> (brewe)
@enduml
....
// end::truncate[]