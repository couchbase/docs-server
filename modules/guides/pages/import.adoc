= Import Data
// Import and Stream Data
:page-topic-type: guide
:imagesdir: ../assets/images
:tabs:
:page-toclevels: 2
:description: How to import documents into Couchbase server.
:github: Click the GitHub button icon:github[] to view this code in context.


[abstract]
{description}

== Introduction

Importing data can be done from the Couchbase Server UI, via the  
xref:tools:cbimport.adoc[cbimport] command-line tool shipped with Couchbase Server,
or using the SDK to script the process.

Data load essentially consists of:

. Prepare data in some well known format such as Comma Separated Values or JSON documents. 
  * Parse this data, and iterate over each document.

. Connect to your Couchbase instance.

. Connect to the appropriate bucket, scope, and collection.

. Decide on the key for this document (could be an ID, a sequence number, or some combination of fields).
  * Do any additional processing if required.
  
. Insert the document.

// tag::clients_section[]
// include::partial$clients.adoc[]
// following section copied/tweaked from above
// differences: cbc vs cbimport, topic, etc.
=== Couchbase Clients

Clients access data by connecting to a Couchbase cluster over the network.
The most common type of client is a Couchbase SDK, which is a full programmatic API that enables applications to take the best advantage of Couchbase.
This developer guide focuses on the most commonly-used SDKs, but full explanations and reference documentation for all SDKs is available.

The command line clients also provide a quick and streamlined interface for simple access and are suitable if you just want to access an item without writing any code. For this guide, we are especially interested in the `cbimport` tool.

[NOTE]
====
With some editions, the command line clients are provided as part of the installation of Couchbase Server.
Assuming a default installation, you can find them in the following location, depending on your operating system:

[horizontal]
Linux:: `/opt/couchbase/bin`
Windows:: `C:\Program Files\Couchbase\Server\bin`
macOS:: `/Applications/Couchbase Server.app/Contents/Resources/couchbase-core/bin`
====

The Couchbase Server UI also offers a graphical interface to `cbimport`.

Read the following for further information about the clients available for importing data:

* xref:tools:cbimport.adoc[cbimport]

* xref:home::sdk.adoc[SDK Clients]

* xref:manage:import-documents/import-documents.adoc[Couchbase Server UI]

// end::clients_section[]

== Preparing the Data

Extract or generate your data in an appropriate data format.

The following are well supported for export as well as by `cbimport` and the module ecosystems of all our SDKs.


[{tabs}]
====
CSV::
+
--
Comma Separated Values (.csv) are easily exported from many spreadsheet and database applications.

Ensure that the first row is a header row containing the names of the columns within the document.

[source,csv]
----
include::nodejs-sdk:howtos:example$import.csv[]
----

--

TSV::
+
--
Tab Separated Values (.tsv) are a common variant of CSV files.

[source,tsv]
----
include::nodejs-sdk:howtos:example$import.tsv[]
----

--

JSON::
+
--
JSON (.json) files are especially well suited to import into Couchbase, as it is the default native datatype.

A .json file contains only one single value, so to give flexibility to import one or many values, format this as an *array* of the values you want to store.

[source,json]
----
include::nodejs-sdk:howtos:example$import.json[]
----
--

JSONL::
+
--
JSON Lines (.json) also known as NDJSON is a common format for streaming JSON, with one JSON object per line of text.

[source,jsonl]
----
include::nodejs-sdk:howtos:example$import.jsonl[]
----
--
====

== Use `cbimport`

Using `cbimport` is straight-forward.
Ensure you have the path to the command line clients in Couchbase Server in your path.

You can import all of the data formats described above:

[{tabs}]
====
CSV::
+
--
[source,console]
----
cbimport csv \
  --dataset -d file://./import.csv \ <.>
  --cluster localhost --username Administrator --password password \ <.>
  --bucket travel-sample --scope-collection-exp inventory.airline \ <.>
  --generate-key %type%_%id% <.>
----
<.> import a local CSV file
<.> replace these values with your connection details
<.> replace the bucket, scope, and collection as required
<.> you need to choose the ID to import as. This generator will generate IDs such as `airline_1234`
--

TSV::
+
--
[source,console]
----
cbimport csv \
  --dataset -d file://./import.tsv --field-separator "\t" \ <.>
  --cluster localhost --username Administrator --password password \ <.>
  --bucket travel-sample --scope-collection-exp inventory.airline \ <.>
  --generate-key %type%_%id% <.>
----
<.> import a local TSV file
<.> replace these values with your connection details
<.> replace the bucket, scope, and collection as required
<.> you need to choose the ID to import as. This generator will generate IDs such as `airline_1234`
--

JSON::
+
--
[source,console]
----
cbimport json \
  --dataset -d file://./import.json --format list \ <.>
  --cluster localhost --username Administrator --password password \ <.>
  --bucket travel-sample --scope-collection-exp inventory.airline \ <.>
  --generate-key %type%_%id% <.>
----
<.> import a local JSON file
<.> replace these values with your connection details
<.> replace the bucket, scope, and collection as required
<.> you need to choose the ID to import as. This generator will generate IDs such as `airline_1234`
--

JSONL::
+
--
[source,console]
----
cbimport json \
  --dataset -d file://./import.jsonl --format lines \ <.>
  --cluster localhost --username Administrator --password password \ <.>
  --bucket travel-sample --scope-collection-exp inventory.airline \ <.>
  --generate-key %type%_%id% <.>
----
<.> import a local JSONL file
<.> replace these values with your connection details
<.> replace the bucket, scope, and collection as required
<.> you need to choose the ID to import as. This generator will generate IDs such as `airline_1234`
--
====


== Import using an SDK

While `cbimport` accomplishes all the necessary steps in a single command, as above,
using an SDK gives you more flexibility and control.
However all the same considerations apply, so let us look at those in turn.

=== Parse the import in`(to an array or stream of records

The details of how to parse the import data vary depending on the most appropriate library for your SDK:

[{tabs}]
====
pass:[.NET]::
+
--
For *CSV* and *TSV*, use the xref:https://joshclose.github.io/CsvHelper/[CsvHelper] library: 

[source,csharp]
----
include::dotnet-sdk:howtos:example$Import.csx[tag=csv-tsv-import,indent=0]
----

[source,csharp]
----
include::dotnet-sdk:howtos:example$Import.csx[tag=importCSV,indent=0]
----

[source,csharp]
----
include::dotnet-sdk:howtos:example$Import.csx[tag=importTSV,indent=0]
----

For *JSON* or *JSONL* format, use xref:https://www.newtonsoft.com/json[Newtonsoft]: 

[source,csharp]
----
include::dotnet-sdk:howtos:example$Import.csx[tag=json-jsonl-import,indent=0]
----
[source,csharp]
----
include::dotnet-sdk:howtos:example$Import.csx[tag=importJSON,indent=0]
----

[source,csharp]
----
include::dotnet-sdk:howtos:example$Import.csx[tag=importJSONL,indent=0]
----

{github}
--

Java::
+
--
For *CSV* and *TSV*, use the xref:http://opencsv.sourceforge.net/[opencsv] library: 

[source,java]
----
include::java-sdk:howtos:example$Import.java[tag=csv-tsv-import,indent=0]
----
[source,java]
----
include::java-sdk:howtos:example$Import.java[tag=importCSV,indent=0]
----

[source,java]
----
include::java-sdk:howtos:example$Import.java[tag=importTSV;-repeated,indent=0]
----

For *JSON*, simply read the file as a string, then use our built-in xref:java-sdk:howtos:json.adoc[JSON] handling to parse the result into an array of JSON objects.

[source,java]
----
include::java-sdk:howtos:example$Import.java[tag=json-jsonl-import,indent=0]
----
[source,java]
----
include::java-sdk:howtos:example$Import.java[tag=importJSON,indent=0]
----

For *JSONL*, do the same, but reading the file line-by-line:

[source,java]
----
include::java-sdk:howtos:example$Import.java[tag=importJSONL;-repeated,indent=0]
----
{github}
--

Node.js::
+
--
For *CSV* and *TSV*, use the xref:https://csv.js.org/parse/[csv-parse] library:

[source,nodejs]
----
include::nodejs-sdk:howtos:example$import.js[tags=csv-tsv-import,indent=0]
----

[source,nodejs]
----
include::nodejs-sdk:howtos:example$import.js[tags=csvStream,indent=0]
----

[source,nodejs]
----
include::nodejs-sdk:howtos:example$import.js[tags=tsvStream,indent=0]
----

For *JSON* or *JSONL* format, use the xref:https://github.com/uhop/stream-json[stream-json] library.

NOTE: stream-json formats its output with a `{ key: ..., value: ...}` wrapper, so we need to map the stream into the expected format.

[source,nodejs]
----
include::nodejs-sdk:howtos:example$import.js[tags=json-jsonl-import,indent=0]
----

[source,nodejs]
----
include::nodejs-sdk:howtos:example$import.js[tags=jsonStream,indent=0]
----

[source,nodejs]
----
include::nodejs-sdk:howtos:example$import.js[tags=jsonlStream,indent=0]
----
{github}
--

Python::
+
--
For *CSV* and *TSV*, use the xref:https://docs.python.org/3/library/csv.html[csv] library:

[source,python]
----
include::python-sdk:howtos:example$import.py[tags=csv-tsv-import,indent=0]
----

[source,python]
----
include::python-sdk:howtos:example$import.py[tags=csvImport,indent=0]
----

[source,python]
----
include::python-sdk:howtos:example$import.py[tags=tsvImport,indent=0]
----

For *JSON* and *JSONL*, use the xref:https://docs.python.org/3/library/json.html[json] library:

[source,python]
----
include::python-sdk:howtos:example$import.py[tags=json-jsonl-import,indent=0]
----

[source,python]
----
include::python-sdk:howtos:example$import.py[tags=jsonImport,indent=0]
----

[source,python]
----
include::python-sdk:howtos:example$import.py[tags=jsonlImport,indent=0]
----
{github}
--
====

=== Connect to the Couchbase Server

First, you need the connection details for the Couchbase server.

Now decide which bucket and xref:learn:data:scopes-and-collections.adoc[scope and collection] you want to import to (and create them if they don't already exist.)

[{tabs}]
====
pass:[.NET]::
+
--
[source,csharp]
----
include::dotnet-sdk:howtos:example$Import.csx[tag=connect,indent=0]
----
{github}

Learn more about xref:dotnet-sdk:howtos:managing-connections.adoc[].
--
Java::
+
--
[source,java]
----
include::java-sdk:howtos:example$Import.java[tag=connect,indent=0]
----
{github}

Learn more about xref:java-sdk:howtos:managing-connections.adoc[].
--
Node.js::
+
--
[source,nodejs]
----
include::nodejs-sdk:howtos:example$import.js[tag=connect,indent=0]
----
{github}

Learn more about xref:nodejs-sdk:howtos:managing-connections.adoc[].
--
Python::
+
--
[source,python]
----
include::python-sdk:howtos:example$import.py[tag=connect,indent=0]
----
{github}

Learn more about xref:python-sdk:howtos:managing-connections.adoc[].
--
====

=== Inserting the documents

Having processed each imported document, you can insert it into the keyspace.

Couchbase is a key-value store, and the document is the value, so before you can insert the document, you need to determine the key.

To insert an imported document into the keyspace:

. Specify the key. This could be as simple as extracting the `id` field from the document, or using an incrementing sequence number.

. Do any additional processing, for example calculating fields, or adding metadata about the importer.

. Finally, use an upsert operation to the store the document.

NOTE: we use `upsert` rather than `insert` to upload the document even if the target key already has a value.
This means that in the case of any error, it is easy to make any required tweaks to the import file and re-run the whole import.

[{tabs}]
====
pass:[.NET]::
+
--
Hook the imports above into an `upsertDocument` routine:

NOTE: as CsvHelper and Newtonsoft generate different outputs, we've provided some overloaded options that work for either.

[source,csharp]
----
include::dotnet-sdk:howtos:example$Import.csx[tag=upsertDocument,indent=0]
----
{github}

Learn more about xref:dotnet-sdk:howtos:kv-operations.adoc[].
--
Java::
+
--
Hook the imports above into an `upsertDocument` routine:

[source,java]
----
include::java-sdk:howtos:example$Import.java[tag=upsertDocument,indent=0]
----
{github}

Learn more about xref:java-sdk:howtos:kv-operations.adoc[].
--
Node.js::
+
--
To iterate the stream you created earlier, use a simple `for` loop in the same way as an array.

[source,nodejs]
----
include::nodejs-sdk:howtos:example$import.js[tag=importStream,indent=0]
----

Hook this in to an `upsertDocument` routine:

[source,nodejs]
----
include::nodejs-sdk:howtos:example$import.js[tag=upsertDocument,indent=0]
----
{github}

Learn more about xref:nodejs-sdk:howtos:kv-operations.adoc[].
--
Python::
+
--
// extracted to functions as there's a multi example below
Define functions to determine the key, and process the value:

[source,python]
----
include::python-sdk:howtos:example$import.py[tag=key,indent=0]
----
[source,python]
----
include::python-sdk:howtos:example$import.py[tag=process,indent=0]
----

Now hook the imports prepared earlier into an `upsertDocument` routine which uses these functions.

[source,python]
----
include::python-sdk:howtos:example$import.py[tag=upsertDocument,indent=0]
----

Learn more about xref:java-sdk:howtos:kv-operations.adoc[].


NOTE: The Python SDK offers a set of batch operations which are marked as _volatile_ as of SDK 3.2.3, which may be more efficient. Here's a brief example for CSV:

[source,python]
----
include::python-sdk:howtos:example$import.py[tags=csvImportMulti,indent=0]
----
{github}
--
====


== Next Steps

* The xref:manage:import-documents:import-documents.adoc[Couchbase Server UI] offers a graphical view of documents, to check your imports interactively.

* The xref:guides:kv-operations.adoc[] guide shows how to read and update the data you have imported. 


////
== Related Links

Reference and explanation:

* xref:n1ql:n1ql-language-reference/join.adoc[JOIN Clause]

Tutorials:

* https://query-tutorial.couchbase.com/tutorial/#1[N1QL Query Language Tutorial^]

See also:

* XDCR
////
