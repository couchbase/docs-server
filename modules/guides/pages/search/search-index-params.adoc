= Search Index JSON Properties

When you xref:guides:search/create-search-index-rest-api.adoc[create a Search index with the REST API], you need to add a JSON payload with the settings for your index.

Your JSON payload must contain the properties described in <<initial,>>, including the <<params,>>.

[#initial]
== Initial Settings 

The start of the JSON payload for a Search index contains important settings for your index: 

[source,json]
----
include::example$search/complex-search-index-payload.jsonc[tag=initial]
----

It contains the following properties: 

[cols="1,1,1,2"]
|====
|Property |Type |Required? |Description

|name |String |Yes |The name of the index.

|type |String |Yes a|

The type of index you want to create: 

* `fulltext-index`: Create a search index.
* `fulltext-alias`: Create an alias for a search index. 
For more information about search index aliases, see xref:[]

|uuid |String |No a|

The UUID for the index. 

The Search Service automatically generates a UUID for an index.

|sourceType |String |Yes |The `sourceType` is always `"gocbcore"`.

|sourceName |String |Yes a|
The name of the bucket where you want to create the index. 

The Search Service automatically finds the UUID for the bucket.

|sourceUUID |String |No |The UUID of the bucket where you want to create the index.

|sourceParams |Object |No a|

This object contains advanced settings for index behavior.

Don't add content into this object unless instructed by Couchbase Support.

|planParams |Object |Yes |An object that sets the index's partitions and replications. 
For more information, see <<planparams,>>.

|params |Object |Yes |An object that sets the index's type identifier, type mappings, and analyzers. 
For more information, see <<params,>>.

|====

[#planparams]

== planParams Object 

The `planParams` object sets an index's partition and replication settings:

[source,json]
----
include::example$search/complex-search-index-payload.jsonc[tag=planparams]
----

It contains the following properties: 

[cols="2,1,1,4"]
|====
|Property |Type |Required? |Description

|maxPartitionsPerPIndex |n/a |No |This setting is deprecated. Use `indexPartitions`, instead.
|indexPartitions |Number |Yes |The number of partitions to split the index into, across the nodes you have available with the Search Service enabled. 
|numReplicas |Number |Yes a|

For high-availability, set the number of replicas the Search Service creates for the index.

You can create up to three replicas for an index. 
To turn off replication for the index, set `numReplicas` to `0`.

The number of replicas you can create depends on the number of nodes you have available with the Search Service enabled. 

|====
[#params]
== Params Object 

The `params` object sets an index's type identifier, type mappings, and analyzers.
It contains the following properties:

[cols="1,1,1,2"]
|====
|Property |Type |Required? |Description 

|doc_config |Object |Yes |An object that sets how the index sets a document's type.
For more information, see <<doc-config,>>.

|mapping |Object |Yes |An object that sets the analyzers and type mappings for an index. 
For more information, see <<mapping,>>.

|====

[#doc-config]
== Doc_config Object

The `doc_config` object sets how the index sets a document's type:

[source,json]
----
include::example$search/complex-search-index-payload.jsonc[tag=doc_config]
----

It contains the following properties: 

[cols="1,1,1,2"]
|====
|Property |Type |Required? |Description

|mode |String |Yes a|

Set how the index identifies a document's type: 

* `type_field`: Use the value from a specific field in the documents. 
* `docid_prefix_delim`: Use the characters in the documents' ID values, up to but not including a specified separator.
* `docid_regexp`: Use a regular expression on the documents' ID values.

NOTE: If your index uses a specific collection, the `mode` value must be `"scope.collection.\{mode\}"`.

|docid_prefix_delim |String |Yes |If `mode` is `docid_prefix_delim`, set the separator character to use on a document's ID value to determine its type.

|docid_regexp |String |Yes |If `mode` is `docid_regexp`, set the regular expression to use on a document's ID value to determine its type. 

|type_field |String |Yes |If `mode` is `type_field`, set the name of the field to use to determine a document's type.

|====

[#mapping]
== Mapping Object 

The `mapping` object contains a search index's analyzers and other xref:guides:search/set-advanced-settings.adoc[advanced settings from the UI].

[source,json]
----
include::example$search/complex-search-index-payload.jsonc[tag=mapping]
----

It contains the following properties:

[cols="2,1,1,4"]
|====
|Property |Type |Required? |Description

|analysis |Object |Yes |An object that contains the <<analyzers,analyzers>>, <<char_filters,char_filters>>, tokenizers, token_filters, <<token_maps,token_maps>>, and <<date_time_parsers,date_time_parsers>> objects.

|default_analyzer |String |Yes a|

The name of the default analyzer to use for the type mapping.

For more information about analyzers, see xref:guides:search/customize-index.adoc#analyzers[Analyzers].

|default_datetime_parser |String |Yes a|
The name of the default date/time parser to use for the type mapping. 

For more information about date/time parsers, see xref:guides:search/customize-index.adoc#date-time[Date/Time Parsers].

|default_field |String |Yes a|
Set a name for the type mapping's `all` field.

If you enable `include_in_all` for a child field, the contents of that child field can be searched by specifying this field's name in your search. 

|default_mapping |Object |No a|

An object that contains settings for the default type mapping on the index. 

The default type mapping contains all documents under the `_default` scope and `_default` collection in the bucket.

This type mapping is included for compatibility only. 

For more information on the properties inside the `default_mapping` object, see <<default-mapping,>>.

|default_type |String |No |This setting is included for compatibility with older indexes only. 

|docvalues_dynamic |Boolean |Yes a|
To include the values for an indexed field in the index, set `docvalues_dynamic` to `true`.

To exclude the values for an indexed field in the index, set `docvalues_dynamic` to `false`.

|index_dynamic |Boolean |Yes a| 

To index any fields in the index where `dynamic` is `true`, set `index_dynamic` to `true`.

To exclude dynamic fields from the index, set `index_dynamic` to `false`.

|store_dynamic |Boolean |Yes a|

To return the content from an indexed field in the index, set `store_dynamic` to `true`.

To exclude field content from the index, set `store_dynamic` to `false`.

|type_field |String |No |Use the same value assigned to the `type_field` in `doc_config`, if applicable.

|types |Object |No a| An object that contains any additional user-defined type mappings for the index, as `\{scope\}.\{collection\}` objects. For more information, see <<types,>>.

|====

[#analyzers]
== Analyzers Object 

The `analyzers` object contains any custom analyzers defined for an index.

It contains any number of `\{analyzer_name\}` objects: 

[source,json]
----
include::example$search/complex-search-index-payload.jsonc[tag=analyzers]
----

The following table describes the available properties for the `analyzers` object:

[cols="1,1,1,2"]
|====
|Property |Type |Required? |Description

|\{analyzer_name\} |Object |Yes a|

The name of this object matches the name of the custom analyzer.

NOTE: The \{analyzer_name\} object contains the `token_filters`, `char_filters`, `type`, and `tokenizer` properties described in the following rows.

|token_filters |Array |Yes |An array of strings that contains the token filters for the custom analyzer. 

|char_filters |Array |Yes |An array of strings that contains the character filters for the custom analyzer. 

|type |String |Yes |The `type` is always `"custom"`.

|tokenizer |String |Yes |The selected tokenizer for the custom analyzer. 

|====

[#char_filters]
== Char_filters Object 

The `char_filters` object contains any custom character filters defined for an index. 

It contains any number of `\{char_filter_name\}` objects: 

[source,json]
----
include::example$search/complex-search-index-payload.jsonc[tag=char_filter]
----

The following table describes the available properties for the `char_filters` object: 

[cols="1,1,1,2"]
|====
|Property |Type |Required? |Description

|\{char_filter_name\} |Object |Yes a|

The name of this object matches the name of the custom character filter. 

NOTE: The \{char_filter_name\} object contains the `regexp`, `replace`, and `type` properties described in the following rows. 

|regexp |String |Yes |The regular expression to use to filter characters from search queries and documents. 

|replace |String |No |The content to insert instead of the content in the `regexp` property. 

|type |String |Yes |The `type` is always `regexp`.

|====

[#tokenizers]
== Tokenizers Object 

The `tokenizers` object contains any custom tokenizers defined for an index. 

It contains any number of `\{tokenizer_name\}` objects: 

[source,json]
----
include::example$search/complex-search-index-payload.jsonc[tag=tokenizers]
----

The following table describes the available properties for the `tokenizers` object: 

[cols="1,1,1,2"]
|====
|Property |Type |Required? |Description

|\{tokenizer_name\} |Object |Yes a|

The name of this object matches the name of the custom tokenizer. 

NOTE: The \{tokenizer_name\} object contains the `type`, `regexp`, `exceptions`, and `tokenizer` properties described in the following rows. 

|exceptions |Array |Yes a| 

If the tokenizer's `type` value is `exception`, define an array of regular expressions to remove from text input to create tokens. 

For example, if you add the characters `sh` as a string to the `exceptions` array, an input string of `shHadshToshGo` has the tokens `Had`, `To`, and `Go`. 

|regexp |String |Yes a| 

If the tokenizer's `type` value is `regexp`, set the regular expression that the tokenizer uses to divide input into tokens. 

The tokenizer takes any matches for the regular expression from the input text stream and uses them as tokens. 

For example, if you use the regular expression `\w*\w`, an input string of `Full Text Search` has the tokens `Full`, `Text`, and `Search`.

|tokenizer |String |Yes a|

If the tokenizer's `type` value is `exception`, give a xref:guides:search/customize-index.adoc#tokenizers[default tokenizer] to apply to the tokens created with the `exceptions` array.

|type |String |Yes a|

The tokenizer's type. Can be one of: 

* `regexp`: The tokenizer uses a regular expression to create tokens.
The tokenizer uses any matches to the regular expression as individual tokens. 
* `exception`: The tokenizer uses an array of regular expressions to remove content and create tokens.
The tokenizer uses any matches to the regular expressions and creates tokens from the surrounding text. 

|====

[#token_filters]
== Token_filters Object 

The `token_filters` object contains any custom token filters defined for an index. 

It contains any number of `\{token_filter__name\}` objects: 

[source,json]
----
include::example$search/complex-search-index-payload.jsonc[tag=token_filters]
----

The following table describes the available properties for the `token_filters` object: 

[cols="1,1,1,2"]
|====
|Property |Type |Required? |Description

|\{token_filter_name\} |Object |Yes a|

The name of this object matches the name of the custom token filter. 

NOTE: The \{token_filter_name\} object contains the `type` property described in the following row. The other properties depend on the value assigned to `type`.

|type |String |Yes a|

The token filter's type. Can be one of: 

* `dict_compound`: Use a wordlist to find and create tokens from compound words in existing tokens. See <<dict_compound,>>.
* `edge_ngram`: Use a set character length to create tokens from the start or end of existing tokens. See <<edge_ngram,>>.
* `elision`: Use a wordlist to remove elisions from input tokens. See <<elision,>>.
* `keyword_marker`: Use a wordlist of keywords to find and create new tokens. See <<keyword_marker,>>.
* `length`: Use a set character length to filter tokens that are too long or too short. See <<length,>>.
* `ngram`: Use a set character length to create new tokens. See <<ngram,>>.
* `normalize_unicode`: Use Unicode Normalization to convert tokens. See <<normalize,>>.
* `shingle`: Use a set character length and separator to concatenate and create new tokens. See <<shingle,>>.
* `stop_tokens`: Use a wordlist to find and remove words from tokens. See <<stop_token,>>.
* `truncate_token`: Use a set character length to truncate existing tokens. See <<truncate_token,>>.

|====

[#dict_compound]
=== Dict_compound Token Filters 

include::partial$search/custom-token-filters-descriptions.adoc[tag=dict]

[cols="1,1,1,2"]
|====
|Property |Type |Required? |Description

|dict_token_map |String |Yes |The wordlist to use to find subwords in existing tokens. 

|====

[#edge_ngram]
=== Edge_ngram Token Filters 

include::partial$search/custom-token-filters-descriptions.adoc[tag=edge]

[cols="1,1,1,2"]
|====
|Property |Type |Required? |Description

|back |Boolean |Yes a|

To create new tokens starting from the end and moving backward in an input token, set `back` to `true`.

To create new tokens starting from the beginning and moving forward in an input token, set `back` to `false`.

|min |Integer |Yes a|

Set the minimum character length for a new token. 

|max |Integer |Yes a|

Set the maximum character length for a new token. 

|====

[#elision]
=== Elision Token Filters

include::partial$search/custom-token-filters-descriptions.adoc[tag=elision]

[cols="1,1,1,2"]
|====
|Property |Type |Required? |Description

|articles_token_map |String |Yes |The wordlist to use to find and remove elisions in existing tokens. 

|====

[#keyword_marker]
=== Keyword_marker Token Filters 

include::partial$search/custom-token-filters-descriptions.adoc[tag=keyword]

[cols="1,1,1,2"]
|====
|Property |Type |Required? |Description

|keywords_token_map |String |Yes |The wordlist to use to find keywords in existing tokens.

|====

[#length]
=== Length Token Filters 

include::partial$search/custom-token-filters-descriptions.adoc[tag=length]

[cols="1,1,1,2"]
|====
|Property |Type |Required? |Description

|min |Integer |Yes |The minimum character length for a new token from the token filter.

|max |Integer |Yes |The maximum character length for a new token from the token filter. 

|====

[#ngram]
=== Ngram Token Filters 

include::partial$search/custom-token-filters-descriptions.adoc[tag=ngram]

[cols="1,1,1,2"]
|====
|Property |Type |Required? |Description

|min |Integer |Yes |The minimum character length for a new token from the token filter.

|max |Integer |Yes |The maximum character length for a new token from the token filter.

|====

[#normalize]
=== Normalize_unicode Token Filters 

include::partial$search/custom-token-filters-descriptions.adoc[tag=normalize]

[cols="1,1,1,2"]
|====
|Property |Type |Required? |Description

|form |String |Yes a|

Select the form of Unicode Normalization to use on input tokens: 

* `nfc`: Use canonical decomposition and canonical composition to normalize characters. The token filter separates combined unicode characters, then merges them into a single character.
* `nfd`: Use canonical decomposition to normalize characters. The token filter separates combined unicode characters. 
* `nfkc`: Use compatibility decomposition to normalize characters. The token filter converts unicode characters to remove variants.
* `nfkd`: Use compatibility decomposition and canonical composition to normalize characters. The token filter removes variants, then separates combined unicode characters to merge them into a single character.

For more information on Unicode Normalization, see the Unicode Consortium's https://unicode.org/reports/tr15/#Introduction[Unicode Normalization Forms^] report.

|====

[#shingle]
=== Shingle Token Filters 

include::partial$search/custom-token-filters-descriptions.adoc[tag=shingle]

[cols="1,1,1,2"]
|====
|Property |Type |Required? |Description

|min |Integer |Yes |The minimum character length for a new token before concatenation.

|max |Integer |Yes |The maximum character length for a new token before concatenation.

|output_original |Boolean |Yes a|

To add the original token to the token filter's output, set `output_original` to `true`.

To exclude the original token from the token filter's output, set `output_original` to `false`.

|separator |String |No |Set a `separator` to include a character or characters in between concatenated tokens. 

|filler |String |No |If another token filter removes a token from the input for this token filter, set a `filler` to replace the removed token.

|====

[#stop_token]
=== Stop_tokens Token Filters 

include::partial$search/custom-token-filters-descriptions.adoc[tag=stop]

[cols="1,1,1,2"]
|====
|Property |Type |Required? |Description

|stop_token_map |String |Yes |The wordlist to use to filter tokens. 
The token filter removes any tokens from input that match an entry in the wordlist.

|====

[#truncate_token]
=== Truncate_token Token Filters 

include::partial$search/custom-token-filters-descriptions.adoc[tag=truncate]

[cols="1,1,1,2"]
|====
|Property |Type |Required? |Description

|length |Integer |Yes a|The maximum character length for an output token. 

|====

[#token_maps]
== Token_maps Object 

The `token_maps` object contains any custom wordlists defined for an index. 

It contains any number of `\{wordlist_name\}` objects: 

[source,json]
----
include::example$search/complex-search-index-payload.jsonc[tag=token_maps]
----

The following table describes the available properties for the `token_maps` object: 

[cols="1,1,1,2"]
|====
|Property |Type |Required? |Description

|\{wordlist_name\} |Object |Yes a|

The name of this object matches the name of the custom wordlist. 

NOTE: The \{wordlist_name\} object contains the `type` and `tokens` properties described in the following rows. 

|type |String |Yes |The `type` is always `"custom"`.

|tokens |Array |Yes |An array of strings that contains each word added to the wordlist. 

|====

[#date_time_parsers]
== Date_time_parsers Object 

The `date_time_parsers` object contains any custom date/time parsers defined for an index. 

It contains any number of `\{date_time_parser_name\}` objects: 

[source,json]
----
include::example$search/complex-search-index-payload.jsonc[tag=date_time]
----

The following table describes the available properties for the `date_time_parsers` object: 

[cols="2,1,1,2"]
|====
|Property |Type |Required? |Description

|\{date_time_parser_name\} |Object |Yes a|

The name of the custom date/time parser. 

NOTE: The `\{date_time_parser_name\}` object contains the `type` and `layouts` properties described in the following rows.

|type |String |Yes |The `type` is always `"flexiblego"`.

|layouts |Array |Yes a|

An array of strings that contains layouts for date and time fields. 

Use a layout from the https://pkg.go.dev/time#pkg-constants[Go Programming Language Time Package's Layout Constant^].

|====

[#default-mapping]
== Default_mapping Object  

The `default_mapping` object contains settings for the default type mapping on the index.
The default type mapping is a legacy feature and only included for compatibility.  

[source,json]
----
include::example$search/complex-search-index-payload.jsonc[tag=default_mapping]
----

The following table describes the available properties for the `default_mapping` object: 

[cols="1,1,1,2"]
|====
|Property |Type |Required? |Description

|dynamic |Boolean |Yes a|
To index all available fields in a document with the default type mapping, set `dynamic` to `true`. 

To only index the fields you specify in the type mapping, set `dynamic` to `false`.

|enabled |Boolean |Yes a|
To enable the Search Service's default type mapping, set `enabled` to `true`. 

The default type mapping includes all documents in the bucket in the index, even if they don't match another configured type mapping.
This can increase index size and indexing time. 

To disable the default type mapping, set `enabled` to `false`.

|====

[#types]
== Types Object

The `types` object contains any additional user-defined type mappings for an index. 

It contains any number of `\{scope\}.\{collection\}` objects: 

[source,json]
----
include::example$search/complex-search-index-payload.jsonc[tag=types]
----

[cols="1,1,1,2"]
|====
|Property |Type |Required? |Description

|`\{scope\}.\{collection\}` |Object |Yes a|

The name of the type mapping. Corresponds to the selected scope and collection where the type mapping applies. For example, `inventory.airline`. 

NOTE: The `\{scope\}.\{collection\}` object contains the `enabled`, `dynamic`, and `properties` properties described in the following rows.

|dynamic |Boolean |Yes a|

To index all fields under the specified scope and collection, set `dynamic` to `true`.

To only index the fields you specify and enable the `properties` block, set `dynamic` to `false`. 

|enabled |Boolean |Yes a| 

To enable the type mapping and include any documents that match it in the index, set `enabled` to `true`. 

To remove any documents that match this type mapping from the index, set `enabled` to `false`.

|properties |Object |No a|

The `properties` object is only enabled if `dynamic` is set to `false`. 

Specifies properties for the fields to index in the type mapping. Contains any number of `\{field_name\}` objects. 

For more information, see <<child-fields,>>

|====

[#child-fields]
=== \{field_name\} Object

The `\{field_name\}` object contains settings and an array for a child field in a type mapping. You can have multiple `\{field_name\}` objects in a `properties` object.

[source,json]
----
include::example$search/complex-search-index-payload.jsonc[tag=child_field]
----

A `\{field_name\}` object contains the following properties:

[cols="1,1,1,2"]
|====
|Property |Type |Required? |Description

|\{field_name\} |Object |Yes a|

The name of the child field you want to index in the type mapping. For example, `city`. 

NOTE: The \{field_name\} object contains the `enabled`, `dynamic`, and `fields` properties described in the following rows.

|enabled |Boolean |Yes a|

To add this child field to the index, set `enabled` to `true`.

To remove this child field from the index, set `enabled` to `false`.

|dynamic |Boolean |No a|This field is included for legacy compatibility only. 

|fields |Array |Yes a|

An array that contains objects with settings for each child field to index in the type mapping.

For more information, see <<fields,>>. 

|====

[#fields]
=== Fields Array 

The `fields` array contains objects with settings for each child field to index in the type mapping:

[source,json]
----
include::example$search/complex-search-index-payload.jsonc[tag=fields]
----

It contains the following properties: 

[cols="1,1,1,2"]
|====
|Property |Type |Required? |Description

|docvalues |Boolean |Yes a|

To include the value for each instance of the field in the index to support xref:[Facets] and sorting search results, set `docvalues` to `true`.

To exclude the values for each instance of this field from the index, set `docvalues` to `false`.

|include_in_all |Boolean |Yes a|

To allow this field to be searched without specifying the specific field's name in the search, set `include_in_all` to `true`.

When enabled, you can search this field through the specified `default_field` set in the type mapping.

To only search this field by specifying the field name, set `include_in_all` to `false`.

|include_term_vectors |Boolean |Yes a|

NOTE: To use term vectors, `store` must be set to `true`.

To allow the Search Service to highlight matching search terms in search results for this field, set `include_term_vectors` to `true`.

To disable term highlighting and reduce index size, set `include_term_vectors` to `false`.

|index |Boolean |Yes a|

To include the child field in the index, set `index` to `true`.

To exclude the child field from the index, set `index` to `false`.

|name |String |Yes |The child field's name.

|store |Boolean |Yes a|

To include the content of the child field in the index and allow its content to be viewed in search results, set `store` to `true`.

To exclude the content of the child field from the index, set `store` to `false`.

|type |String |Yes a|

The child field's type. Can be one of:

* `text`
* `number`
* `datetime`
* `boolean`
* `geopoint`
* `geoshape`
* `disabled`

For more information on the available field data types, see xref:guides:search/field-data-types-reference.adoc[].

|analyzer |String |No a|

If the child field's `type` is `text`, set the analyzer to use for the child field. 

NOTE: If you want to use the default analyzer for the content of this child field, you don't need to include an `analyzer` property.  

|====