= Default Analyzers 
:page-topic-type: reference

When you xref:guides:search/create-type-mapping.adoc[create a type mapping], you can choose a default analyzer for your type mappings, or xref:guides:search/create-custom-analyzer.adoc[create your own].

Analyzers use character filters, tokenizers, and token filters to filter and modify search strings and improve matches for a search. 
For more information about analyzers and their components, see xref:guides:search/customize-index.adoc[].

The following default analyzer options are available: 

|====
|Analyzer |Description 

|inherit | Set the analyzer for a type mapping to `inherit` to inherit the default analyzer set for an index. 

|ar |The `ar` analyzer uses character filters, tokenizers, and token filters designed for Arabic language searches.

|cjk |The `cjk` analyzer uses character filters, tokenizers, and token filters designed for Chinese, Japanese and Korean language searches.

|ckb |The `ckb` analyzer uses character filters, tokenizers, and token filters designed for Kurdish language searches.

|da |The `da` analyzer uses character filters, tokenizers, and token filters designed for Danish language searches.

|de |The `de` analyzer uses character filters, tokenizers, and token filters designed for German language searches.

|en |The `en` analyzer uses character filters, tokenizers, and token filters designed for English language searches.

|es |The `es` analyzer uses character filters, tokenizers, and token filters designed for Castilian Spanish language searches.

|fa |The `fa` analyzer uses character filters, tokenizers, and token filters designed for Persian language searches.

|fi |The `fi` analyzer uses character filters, tokenizers, and token filters designed for Finnish language searches.

|fr |The `fr` analyzer uses character filters, tokenizers, and token filters designed for French language searches.

|he |The `he` analyzer uses character filters, tokenizers, and token filters designed for Hebrew language searches.

|hi |The `hi` analyzer uses character filters, tokenizers, and token filters designed for Hindi language searches.

|hr |The `hr` analyzer uses character filters, tokenizers, and token filters designed for Croatian language searches.

|hu |The `hu` analyzer uses character filters, tokenizers, and token filters designed for Hungarian language searches.

|it |The `it` analyzer uses character filters, tokenizers, and token filters designed for Italian language searches.

|keyword a|

The `keyword` analyzer turns input into a single token. It forces exact matches and preserves whitespace characters like spaces. 

For example, the `keyword` analyzer turns an input of `Couchbase Server` into a single token: `Couchbase Server`.

|nl |The `nl` analyzer uses character filters, tokenizers, and token filters designed for Dutch language searches.

|no |The `no` analyzer uses character filters, tokenizers, and token filters designed for Norwegian language searches.

|pt |The `pt` analyzer uses character filters, tokenizers, and token filters designed for Portuguese language searches.

|ro |The `ro` analyzer uses character filters, tokenizers, and token filters designed for Romanian language searches.

|ru |The `ru` analyzer uses character filters, tokenizers, and token filters designed for Russian language searches.

|simple a|

The `simple` analyzer turns input into tokens based on letter characters. It removes characters like punctuation and numbers, and uses these characters as the boundaries for tokens. 

For example, the `simple` analyzer turns an input of `Couchbase Server` into two tokens: `Couchbase` and `Server`.

|standard a|

The `standard` analyzer uses the xref:guides:search/customize-index.adoc#unicode[`unicode` tokenizer] with the xref:guides:search/default-token-filters-reference.adoc#to-lower[`to_lower`] and xref:guides:search/default-token-filters-reference.adoc#stop-en[`stop_en`] token filters. 

For example, the `standard` analyzer turns an input of `The name is Couchbase Server` into three tokens: `name`, `couchbase`, and `server`.

|sv |The `sv` analyzer uses character filters, tokenizers, and token filters designed for Swedish language searches.

|tr |The `tr` analyzer uses character filters, tokenizers, and token filters designed for Turkish language searches.

|web a|

The `web` analyzer finds email addresses, URLs, Twitter usernames, and hashtags in its input and turns them into tokens. 

For example, the `web` analyzer turns an input of `Send #Couchbase to example@gmail.com` into four tokens: `send`, `#Couchbase`, `to`, and `example@gmail.com`.

|====