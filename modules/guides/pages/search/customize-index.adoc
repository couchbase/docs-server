= Customize a Search Index 
:page-topic-type: concept
:description: Customize a Search Index 

You can customize your Search indexes with <<type-mappings,>> and <<analyzers,>> to improve performance and the quality of your search results. 

[#type-mappings]
== Type Mappings

Use a type mapping to include or exclude specific documents in a scope or collection from an index. 

You can create two types of type mappings: 

* *Dynamic type mappings*: Add all available fields from their document type to an index. 
* *Static type mappings*: Add only specific fields from their document type to an index. 

By default, all indexes have a dynamic type mapping that includes all documents from the *_default* scope and *_default* collection in a bucket. 

Add xref:guides:search/create-child-field.adoc[child fields] to create a static type mapping.
Child fields set the specific fields from a document that you want to include or exclude from an index. 

For more information about how to add a type mapping to an index, see xref:guides:search/create-search-index-ui.adoc[].

[#analyzers]
== Analyzers

Use analyzers to improve and customize the search results in your index.  

Analyzers transform input text into tokens, which give you greater control over your index's text matching.  

You can use one of Couchbase's built-in analyzers or create your own. 
For more information about how to create a custom analyzer, see xref:guides:search/create-custom-analyzer.adoc[].

Analyzers have different components that control how text is transformed for search. 
When you create a custom analyzer, you can choose these components. 

Both custom and default analyzers can contain the following components: 

* <<character-filters,>>
* <<tokenizers,>>
* <<token-filters,>>
* <<wordlists,>>

[#character-filters]
=== Character Filters 

Character filters remove unwanted characters from the input for a search. 

For example, the default *html* character filter removes HTML tags from your search content. 

You can use a default character filter in an analyzer or create your own. 

The following default character filters are available: 

|====
|Character Filter |Description

|asciifolding | The analyzer converts any characters from

|html a|

The analyzer removes all HTML tags from search input. 

For example, the character filter removes the <p> tags from indexed content, but keeps the text inside the <p> tag.

|zero_width_spaces |The analyzer replaces zero-width non-joiner spaces with regular space characters.

|====

For more information about how to create your own custom character filter, see xref:guides:search/create-custom-character-filter.adoc[].

[#tokenizers]
=== Tokenizers 

Tokenizers separate input strings into individual tokens. 
These tokens are combined into token streams. 
The Search Service takes token streams from search queries to determine matches for token streams in search results. 

You can use a default tokenizer in an analyzer or create your own. 

The following default tokenizers are available: 

|====
|Tokenizer |Description 

|hebrew |Separates an input string into tokens that contain only Hebrew alphabet characters. Punctuation marks and numbers are excluded.

|letter |Separates an input string into tokens that contain only Latin alphabet characters. Punctuation marks and numbers are excluded.

|single |Creates a single token from the input string. Special characters and whitespace are preserved.

|[#unicode]unicode |Separates input strings into tokens based on http://www.unicode.org/reports/tr29/#Word_Boundaries[Unicode Word Boundaries^]. 

|web |Creates tokens from an input string that match email address, URL, Twitter username, and hashtag patterns.

|whitespace |Separates an input string into tokens based on the location of whitespace characters.

|====

For more information about how to create your own tokenizer, see xref:guides:search/create-custom-tokenizer.adoc[].

[#token-filters]
=== Token Filters 

Token filters take the token stream from a tokenizer and modify the tokens. 

A token filter can create stems from tokens to increase the matches for a search term. 

For example, if a token filter creates the stem `play`, a search can return matches for `player`, `playing`, and `playable`.

The Search Service has many default tokenizers available.
For a list of all available tokenizers, see xref:guides:search/default-token-filters-reference.adoc[].

You can also create your own token filters. 
Custom token filters can use <<wordlists,>> to modify their tokens. 
For more information about how to create your own token filter, see xref:guides:search/create-custom-token-filter.adoc[].

[#wordlists]
=== Wordlists 

Wordlists define a list of words to ... 

When you create a custom <<token-filters,token filter>>, the Search Service has a set of default wordlists: 


For more information about how to create a wordlist, see xref:guides:search/create-custom-wordlist.adoc[].