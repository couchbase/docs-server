= Create a Custom Token Filter
:tabs:
:page-topic-type: guide
:page-toc-levels: 3

== Prerequisites 

* You've logged in to the Couchbase Server Web Console or Capella UI. 

== Procedure 

[{tabs}]
====
Couchbase Server::
+
--
. Go to *Search*. 
. Do one of the following: 
.. To create a custom token filter on an existing Search Index, click an index. Then, click btn:[Edit].
.. To create a custom token filter on a new Search Index, click btn:[Add Index].
. Expand *Customize Index*. 
. Expand *Custom Filters*. 
. Click btn:[Add Token Filter].
. In the *Name* field, enter a name for the token filter.

include::partial$search/custom-token-filter-tf-list.adoc[]

--

Couchbase Capella::
+
--
. From your organization page, select the database where you want to create a custom token filter. 
. Go to menu:Data Tools[Search].
. Do one of the following: 
.. To create a custom token filter on an existing Search Index, click the index name.
.. To create a custom token filter on a new Search Index, click btn:[Add Search Index].
. Expand *Advanced Configuration*. 
. Expand *Custom Filters*. 
. Click btn:[Add Token Filter].
. In the *Name* field, enter a name for the token filter.

include::partial$search/custom-token-filter-tf-list.adoc[]

--

====



[#dict-compound]
=== Create a Custom `dict_compound` Token Filter

include::partial$search/custom-token-filters-descriptions.adoc[lines=2..3;9..27]

To create a new `dict_compound` token filter:
 
. In the *Type* field, select *dict_compound*. 
. In the *Sub Words* list, select the wordlist to use to find subwords in input tokens.
+
You can choose your own xref:guides:search/create-custom-wordlist.adoc[custom wordlist] or a xref:guides:search/default-wordlists-reference.adoc[default wordlist]. Each subword match creates a new token. 
. Click btn:[Save]. 

[#edge-ngram]
=== Create a Custom `edge_ngram` Token Filter 

include::partial$search/custom-token-filters-descriptions.adoc[lines=31..32;38..56]

To create a new `edge_ngram` token filter:

. In the *type* field, select *edge_ngram*.
. Do one of the following: 
.. To create new tokens starting from the end of input tokens, select *Back*. 
.. To create new tokens starting from the beginning of input tokens, clear *Back*. 
. In the *Min* field, enter the minimum character length for a new token. 
. In the *Max* field, enter the maximum character length for a new token.
. Click btn:[Save].

[#elision]
=== Create a Custom `elision` Token Filter

include::partial$search/custom-token-filters-descriptions.adoc[lines=60;66..85]

To create a new `elision` token filter:

. In the *Type* field, select *elision*. 
. In the *Articles* list, select a wordlist to use to find elisions in input tokens.
+
You can choose your own xref:guides:search/create-custom-wordlist.adoc[custom wordlist] or a xref:guides:search/default-wordlists-reference.adoc[default wordlist].
. Click btn:[Save]. 

[#keyword-marker]
=== Create a Custom `keyword_marker` Token Filter 

include::partial$search/custom-token-filters-descriptions.adoc[lines=89;95..110]

To create a new `keyword_marker` token filter:

. In the *Type* field, select *keyword_marker*. 
. In the *Keywords* list, select a wordlist to use to find keywords to create tokens.
+
You can choose your own xref:guides:search/create-custom-wordlist.adoc[custom wordlist] or a xref:guides:search/default-wordlists-reference.adoc[default wordlist].
. Click btn:[Save]. 

[#length]
=== Create a Custom `length` Token Filter 

include::partial$search/custom-token-filters-descriptions.adoc[lines=114;120..134]

To create a new `length` token filter:

. In the *Type* field, select *length*. 
. In the *Min* field, enter the minimum character length for a new token. 
. In the *Max* field, enter the maximum character length for a new token.
. Click btn:[Save].

[#ngram]
=== Create a Custom `ngram` Token Filter

include::partial$search/custom-token-filters-descriptions.adoc[lines=138;144..160]

To create a new `ngram` token filter:

. In the *Type* field, select *ngram*. 
. In the *Min* field, enter the minimum character length for a new token. 
. In the *Max* field, enter the maximum character length for a new token.
. Click btn:[Save].

[#normalize-unicode]
=== Create a Custom `normalize_unicode` Token Filter 

include::partial$search/custom-token-filters-descriptions.adoc[lines=164]

To create a new `normalize_unicode` token filter:

. In the *Type* field, select *normalize_unicode*. 
. In the *Form* list, select the type of Unicode normalization to apply: 
+
* *nfc*: Use canonical decomposition and canonical composition to normalize characters. The token filter separates combined unicode characters, then merges them into a single character.
* *nfd*: Use canonical decomposition to normalize characters. The token filter separates combined unicode characters.
* *nfkc*: Use compatibility decomposition to normalize characters. The token filter converts unicode characters to remove variants.
* *nfkd*: Use compatibility decomposition and canonical composition to normalize characters. The token filter removes variants, then separates combined unicode characters to merge them into a single character.
. Click btn:[Save].

[#shingle]
=== Create a Custom `shingle` Token Filter 

include::partial$search/custom-token-filters-descriptions.adoc[lines=173;179..196]

To create a new `shingle` token filter:

. In the *Type* field, select *shingle*.
. In the *Min* field, enter the minimum character length for a new token before concatenation. 
. In the *Max* field, enter the maximum character length for a new token before concatenation.
. Do one of the following: 
.. To include the original token as an output token, select *Include original token*. 
.. To remove the original token from output, clear *Include original token*. 
. (Optional) In the *Separator* field, enter a character or characters to add in between concatenated tokens. 
. (Optional) In the *Filler* field, enter a character or characters to replace tokens that are removed by another token filter.
. Click btn:[Save].

[#stop-tokens]
=== Create a Custom `stop_tokens` Token Filter

include::partial$search/custom-token-filters-descriptions.adoc[lines=200;206..224]

To create a new `stop_tokens` token filter:

. In the *Type* field, select *stop_tokens*. 
. In the *Stop Words* list, select a wordlist to use to remove tokens.
+
You can choose your own xref:guides:search/create-custom-wordlist.adoc[custom wordlist] or a xref:guides:search/default-wordlists-reference.adoc[default wordlist].
. Click btn:[Save].

[#truncate-token]
=== Create a Custom `truncate_token` Token Filter 

include::partial$search/custom-token-filters-descriptions.adoc[lines=228;234..254]

To create a new `truncate_token` token filter:

. In the *Type* field, select *truncate_token*.
. In the *Length* field, enter the maximum character length for an output token. 
. Click btn:[Save].