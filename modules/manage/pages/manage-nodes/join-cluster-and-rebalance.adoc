= Join a Cluster and Rebalance
:description: An independent Couchbase Server-node can be joined to an existing cluster.

[abstract]
{description}

[#understanding-the-join-operation]
== Understanding the Join Operation

_Full_ and _Cluster_ administrators can use the UI or REST API to join a Couchbase Server nodes to an existing cluster. On each node to be added, Couchbase Server must have been _installed and started_.
The process of node-addition grants to the new node the settings already established for the parent cluster.
(See xref:manage:manage-settings/manage-settings.adoc[Manage Settings] for details.)
The process allow services to be assigned to the new node.
If the new node was previously _initialized_ with custom disk-paths, these are retained (although if the UI is used for the join operation, these paths can be revised).

Following node-addition, _rebalance_ is required, to make the new node
and active member of the cluster.

Note that this process has a similar effect to that described in xref:manage:manage-nodes/add-node-and-rebalance.adoc[Add a Node and Rebalance].
The difference is that here, the process is inverted: rather than a cluster adding a node to itself, a node is joining itself to a cluster.

Note also, however, that a node _cannot_ join itself to a cluster if the node has already been provisioned (that is, has had Full Administrator username and password defined, and may also have had services and memory quotas defined).
If the node has been provisioned, the cluster must _add_ the node.

=== Node-Joining and Certificate-Management

The examples on this page assume that the default, _system-generated_ certificates provided by Couchbase Server continue to be resident on the cluster and the node to be added.
In a production or similar context, to ensure security, only administrator-configured certificates should be used on a cluster: these should rely on a well known _Certificate Authority_, whose certificate is loaded as the cluster's _root_ certificate.
(For more information, see xref:learn:security/certificates.adoc#server-certificates[Default Certificates and Certificate Substitution].)

In such a context, no node can be joined to the cluster until conformant administrator-configured certificates have been loaded onto it -- such activities will thus need to be performed in addition to those shown by the examples on this page.

For more information, see xref:manage:manage-security/configure-server-certificates.adoc#adding-new-nodes[Adding and Joining New Nodes].
A complete overview of Couchbase-Server certificate-management is provided in xref:learn:security/certificates.adoc[Certificates].

==== Joining Nodes Securely

In production and similar contexts, nodes should be joined over a secure connection.
This can be achieved by explicitly specifying the secure port `18091`, when providing a hostname for the cluster that is to be joined.

[#examples-on-this-page-node-addition]
== Examples on This Page

The examples in the subsections below show how the same uninitialized and unprovisioned node joins itself to the same existing cluster, using the xref:manage:manage-nodes/join-cluster-and-rebalance.adoc#join-a-cluster-with-the-ui[UI] and the xref:manage:manage-nodes/join-cluster-and-rebalance.adoc#join-a-cluster-with-the-rest-api[REST API] respectively.
Node-join is not supported by the CLI.

The examples assume:

* A one-node cluster already exists; and is named after its IP address: `10.142.181.101`.
It is running the Data, Query, and Index services, and has the `travel-sample` bucket installed.
(To access and install this, see xref:manage:manage-settings/install-sample-buckets.adoc[Sample Buckets].)

* A new node has been started. This is named after its IP address: `10.142.181.101`. It has not been initialized or provisioned.

* The cluster has the Full Administrator username of `Administrator`, and password of `password`.

* The default,  _system-generated_ certificates provided by Couchbase Server continue to be resident on the cluster and the node to be joined.

[#join-a-cluster-with-the-ui]
== Join a Cluster with the UI

Proceed as follows:

. Acccess the new node's Couchbase Web Console instance, at `10.142.181.102:8091`.
The welcome screen is displayed:
+
[#new-node-welcome-screen]
image::manage-nodes/newNodeWelcomeScreen.png[,400,align=middle]

. Left-click on the *Join Existing Cluster* button:
+
[#join-existing-cluster-button]
image::manage-nodes/joinExistingClusterButton.png[,230,align=middle]
+
This brings up the *Join Cluster* dialog:
+
[#join-cluster-dialog]
image::manage-nodes/joinClusterDialog.png[,400,align=middle]

. Left-click on the *Configure Services & Setings For This Node* control.
The dialog expands vertically, as follows:
+
[#join-cluster-dialog-expanded]
image::manage-nodes/joinClusterDialogExpanded.png[,400,align=middle]
+
The expanded dialog allows specification of the services, the name and IP address, and the disk paths for the new node.
It also requires the username and password of the *Cluster Admin* (although the credentials of the *Full Admin* for the cluster are equally implied), and the name or IP address of the cluster to be joined.

. Enter the cluster's IP address (in this case, `10.142.181.101`) and password, and uncheck all *Services* fields except *Data*. Leave all other details unchanged. Then, left-click on the *Join With Custom Configuration* button, at the lower right.
+
The dashboard for the cluster now appears.
The following notification is provided at the lower left:
+
[#server-association-message]
image::manage-nodes/serverAssociationMessage.png[,220,align=middle]

. Access the *Servers* screen, by left-clicking on the *Servers* tab, on the left-hand navigation bar.
The display is as follows:
+
[#servers-screen-with-node-added]
image::manage-nodes/twoNodeClusterAfterAddNodeExpanded.png[,800,align=middle]
+
This indicates that the new node, `10.142.181.102` has successfully joined the cluster.
However, it is not yet taking traffic, and will be added following a _rebalance_.
Note, at this point, the figure under the *Items* column for for `10.142.181.101`: this is `31.1 K/0`, which indicates that the node contains 3.1 K items in _active_ vBuckets, and 0 items in _replica_ vBuckets.
Meanwhile, the *Items* figure for `10.142.181.102` is 0/0, indicating that no items are yet distributed onto that node in either active or replica form.
+
To access information on buckets, vBuckets, and intra-cluster replication, see the architecture  xref:learn:architecture-overview.adoc[Overview].

. To rebalance the cluster, and thereby fully add the new node, left-click on the *Rebalance* button, at the upper right:
+
[#rebalance-button]
image::manage-nodes/rebalanceButton.png[,140,align=middle]
+
Rebalance occurs.
A progress dialog is shown:
+
[#rebalance-progress-join-node]
image::manage-nodes/rebalanceProgressJoinNode.png[,400,align=middle]
+
Following rebalance, the *Servers* display reflects the successful outcome:
+
[#servers-screen-with-node-added-after-rebalance]
image::manage-nodes/twoNodeClusterAfterRebalance.png[,800,align=middle]
+
This indicates that cluster `10.142.181.101` now contains two fully functioning nodes, which are `10.142.181.101` and `10.142.181.102`.
(Note that the figure in the *Items* column for node `10.142.181.101` is `15.2 K/15.8 K`, which indicates that 15.2 K items are stored on the node in _active_ vBuckets, and 15.8 K in _replica_ vBuckets.
The figure for `10.142.181.102` indicates the converse.
Therefore, replication has successfully distributed the contents of `travel-sample` across both nodes, providing a single replica vBucket for each active vBucket.)

Note that if rebalance fails, notifications are duly provided.
These are described in xref:manage:manage-nodes/add-node-and-rebalance.adoc#rebalance-failure-notification[Rebalance Failure Notification].
See also the information provided on xref:manage:manage-nodes/add-node-and-rebalance.adoc#automated-rebalance-failure-handling[Automated Rebalance-Failure Handling], and the procedure for its set-up, described in xref:manage:manage-settings/general-settings.adoc#rebalance-settings[Rebalance Settings].

[#join-a-cluster-with-the-rest-api]
== Join a Cluster with the REST API

To join a node to a cluster with the REST API, use the `/node/controller/doJoinCluster` URI.
Enter the following:

----
curl -u Administrator:password -v -X POST \
http://10.142.181.102:8091/node/controller/doJoinCluster \
-d 'hostname=10.142.181.101&user=Administrator&password=password&services=kv'
----

The `hostname` and `user`(-name) and `password` of the Full Administrator for the cluster to be joined are specified.
The service specified to be run on the new node is `kv`, signifying the Data Service.

At this point, the newly joined node must be rebalanced into the cluster.
Use the `/controller/rebalance` URI, as follows:

----
curl -u Administrator:password -v -X POST \
10.142.181.101:8091/controller/rebalance \
-d 'knownNodes=ns_1@10.142.181.101,ns_1@10.142.181.102'
----

Note that the `knownNodes` argument lists each of the nodes in the cluster.
If successful, the command returns no output.

For further information on joining a cluster with the REST API, see xref:rest-api:rest-cluster-joinnode.adoc[Joining Nodes into Clusters]; on rebalancing, see xref:rest-api:rest-cluster-rebalance.adoc[Rebalancing Nodes].


[#next-steps-after-joining-and-rebalancing]
== Next Steps

Couchbase Server allows you to list the nodes within a cluster.
See xref:manage:manage-nodes/list-cluster-nodes.adoc[List Cluster Nodes] for details.
