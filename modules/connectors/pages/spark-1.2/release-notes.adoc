[#concept_cn2_5ck_r5]
= Release Notes

[abstract]
Release notes for the 1.2 version of the Spark connector.

== Couchbase Spark Connector 1.2.1 GA (June 2016)

*Spark Core*

* The underlying SDK has been updated to 2.3.0
* https://www.couchbase.com/issues/browse/SPARKC-52[SPARKC-52]: `SaveMode` on writes now doesn't bubble up errors if `IGNORE` is used.
* https://www.couchbase.com/issues/browse/SPARKC-51[SPARKC-51]: Added JVM hook to eventually clean up connections properly.
* https://www.couchbase.com/issues/browse/SPARKC-56[SPARKC-56]: Support for transparent retry on writes like on reads.

*Spark SQL*

* https://www.couchbase.com/issues/browse/SPARKC-50[SPARKC-50]: The `(META_)ID` can now be any type which can be converted into a string instead of being an actual string.
This allows for more flexibility in working with types in the first place.
* https://www.couchbase.com/issues/browse/SPARKC-48[SPARKC-48]: Filters that are `LIKE` based now escape `.` and `*` chars.
* https://www.couchbase.com/issues/browse/SPARKC-53[SPARKC-53]: Deeply nested attributes on filters are properly parsed and escaped.

*Spark Streaming*

* https://www.couchbase.com/issues/browse/SPARKC-55[SPARKC-55]: The `FromNow` option now works, allowing you to start streaming from the current point in time without getting all the previous mutations first.

== Couchbase Spark Connector 1.2.0 GA (May 2016)

*Spark Core*

* Support for Apache Spark 1.6.x
* https://www.couchbase.com/issues/browse/SPARKC-37[SPARKC-37]: Both Java and Scala APIs now export Couchbase view, spatial view, and N1QL query APIs on RDDs in addition to the `SparkContext`.
* https://www.couchbase.com/issues/browse/SPARKC-46[SPARKC-46]: Subdocument Lookups are supported on the RDDs and the SparkContext (only supported with Couchbase Server 4.5).

*Spark SQL*

* https://www.couchbase.com/issues/browse/SPARKC-41[SPARKC-41]: Manual override of the `schemaFilter` has been fixed.
It is now possible to define a filter like this:
+
[source,scala]
----
sqlContext.read
  .option("bucket","travel-sample")
  .option("schemaFilter", "type = 'airline'")
  .couchbase()
----

* https://www.couchbase.com/issues/browse/SPARKC-42[SPARKC-42]: The SparkSQL `count()` operator now works, a bug has been fixed so that if SparkSQL doesn't pass in required columns they are transformed to a `*` query.
* https://www.couchbase.com/issues/browse/SPARKC-30[SPARKC-30]: It is now possible to provide a manual schema as well as a custom schema filter.
* https://www.couchbase.com/issues/browse/SPARKC-43[SPARKC-43]: The Java API can now use Spark SQL directly.
See the Java API documentation for more information.
* https://www.couchbase.com/issues/browse/SPARKC-47[SPARKC-47]: SparkSQL Filter expression support has been extended to support all Spark Filters, including nested ones.

*Spark Streaming*

* The internal implementation has been updated to the latest release but *is still experimental*.
Note that the `FromBeginning` is implemented, but `FromNow` still has some known issues which will be fixed in later releases.
Also, cluster rebalance support is not yet available and will follow.
