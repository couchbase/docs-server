[#concept_cn2_5ck_r5]
= Release Notes

[abstract]
Release notes for the 2.0 version of the Kafka connector.

== Couchbase Kafka Connector 2.0.1 GA (8 August 2016)

This is minor GA release.
It contains several bug fixes:

* https://www.couchbase.com/issues/browse/KAFKAC-39[KAFKAC-39]:
+
Allow changing the default timeout for socket connection through environment.
+
[source,java]
----
DefaultCouchbaseKafkaEnvironment.Builder builder =
                (DefaultCouchbaseKafkaEnvironment.Builder) DefaultCouchbaseKafkaEnvironment
                        .builder()
                        .kafkaTopic("default")
                        .kafkaZookeeperAddress("kafka1.vagrant")
                        .couchbaseNodes("couchbase1.vagrant")
                        .couchbaseBucket("default")
                        .connectTimeout(10) // sets timeout to 10 seconds
                        .dcpEnabled(true);
        CouchbaseKafkaConnector connector = CouchbaseKafkaConnector.create(builder.build());
----

* Fix Java 7 compatibility.

== Couchbase Kafka Connector 2.0.0 GA (30 March 2016)

Version 2.0.0 is the general availability (GA) release of the Kafka connector.
It contains important stability fixes, and also new API.

*New features and behavioral changes*

This release contains the following features:

* https://www.couchbase.com/issues/browse/KAFKAC-27[KAFKAC-27], https://www.couchbase.com/issues/browse/KAFKAC-29[KAFKAC-29], https://www.couchbase.com/issues/browse/KAFKAC-32[KAFKAC-32], https://www.couchbase.com/issues/browse/KAFKAC-30[KAFKAC-30], https://www.couchbase.com/issues/browse/KAFKAC-33[KAFKAC-33]:
+
All these issues share a common root cause.
If the Kafka consumer handles new events at a slower rate than the DCP producer emits them, then all additional messages are dropped silently.
Eventually, because most of these messages carry native buffers that cannot be freed by GC, the connector eventually dies from out-of-memory exceptions.
+
Fixing these issues required a new implementation of the DCP handler inside the JVM Core.
Some classes were removed (such as `BucketStreamAggregator` and `BucketStreamAggregatorState`) and new, cleaner alternatives were introduced (such as `ConnectorState` and `StreamState`).
These new classes encapsulate only one point in history, in contrast to the old classes that carried a starting and an ending sequence number.
These alternatives replace the unintuitive direction and run-mode API with a method that accepts two states plus some helper methods that make it easier to initialize `ConnectorState`.
For example, the following code:
+
[source,java]
----
BucketStreamAggregatorState state = connector.buildState(Direction.TO_CURRENT);
connector.run(state, RunMode.RESUME);
----
+
can be simplified as
+
[source,java]
----
ConnectorState startState = connector.startState();
ConnectorState currentState = connector.currentState();
connector.run(startState, currentState);
----
+
and the snippet
+
[source,java]
----
BucketStreamAggregatorState state = connector.buildState(Direction.FROM_CURRENT);
connector.run(state, RunMode.LOAD_AND_RESUME);
----
+
becomes
+
[source,java]
----
ConnectorState loadedState = connector.loadState();
ConnectorState endState = connector.endState();
connector.run(loadedState, endState);
----

* https://www.couchbase.com/issues/browse/KAFKAC-32[KAFKAC-32]:
+
Zookeeper state serializer now uses the forward slash `/` as a path separator, which makes it platform independent.
Before this change, a  connector running on Windows used a backward slash and other platforms used a forward slash.

*Known issues*

This release does not handle cluster topology changes.
For example, it does not add streams for partitions that are migrated between nodes during a rebalance.
The API for the necessary enhancements to handle cluster topology changes is still under discussion.
Corresponding JIRA tickets are: https://www.couchbase.com/issues/browse/JVMCBC-307[JVMCBC-307] and https://www.couchbase.com/issues/browse/KAFKAC-7[KAFKAC-7].
