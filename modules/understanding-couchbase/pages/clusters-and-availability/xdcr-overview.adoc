= Cross Data Center Replication (XDCR)

[abstract]
_Cross Data Center Replication_ (XDCR) allows data to be replicated across clusters
that are potentially located in different data centers.

[#introduction-to-xdcr]
== Introduction to XDCR

Cross Data Center Replication (XDCR) replicates data between clusters: this
provides protection against data center failure, and also provides
high-performance data-access for globally distributed, mission-critical
applications.

XDCR replicates data from a specific bucket on the source cluster to a
specific bucket on the target cluster. Data from the source bucket is pushed
to the target bucket by means of an XDCR agent, running on the source cluster,
using the Database Change Protocol. Any bucket (Couchbase or Ephemeral) on any
cluster can be specified as a source or a target for one or more
XDCR definitions.

Cross Data Center Replication differs from intra-cluster replication in
the following, significant ways:

* Whereas intra-cluster replication creates only _replica_ vBuckets, XDCR
creates only _active_ vBuckets, which duly become available for the serving of
data on the target cluster.
* Whereas intra-cluster replication is configured and performed with
reference to only a single bucket (to which all active and replica vBuckets
will correspond), XDCR requires _two_ buckets to be administrator-specified,
for a replication to occur: one is the bucket on the source cluster, which
provides the data to be replicated; the other is the bucket on the target
cluster, which receives the replicated data.
* Whereas intra-cluster replication is configured at bucket-creation, XDCR
is configured _following_ the creation of both the source and target buckets.

XDCR is started, paused, and stopped independently of the process of
intra-cluster replication on either source or target cluster. The XDCR
process continuously
propagates mutations from the source to the target bucket. The source and
target clusters can have different node-configurations. The source and
target buckets can have different intra-cluster replication settings.

[#tools-for-managing-xdcr]
== Tools and Procedures for Managing XDCR

XDCR is managed in three stages:

. Define a _reference_ to a remote cluster, which will be the target for
Cross Data Center Replication.
. Define and start a _replication_, which continuously transfers mutations
from a specified source bucket to a specified target bucket.
. Monitor the process, pausing and stopping if and when appropriate.

Couchbase provides three options for managing these stages, which are
by means of:

* _Couchbase Web Console_, which provides a graphical user interface for
interactive configuration and management of replications.
* _CLI_, which provides commands and flags that allow replications to be
managed from the command line.
* _REST API_, which underlies both the Web Console and CLI, and can be
expressed either as a `curl` command on the command line, or within a
program or script.

[#xdcr-direction-and-topology]
== XDCR Direction and Topology

XDCR allows replication to occur between source and target clusters in
either of the following ways:

* _Unidirectionally_: The data contained in a specified source bucket is
replicated to a specified target bucket. Although the replicated data on
the source _could_ be used for the routine serving of
data, it is in fact intended
principally as
a backup, to support disaster recovery.
* _Bidirectionally_: The data contained in a specified source bucket is
replicated to a specified target bucket; and the data contained in the
target bucket is, in turn, replicated back to the source
bucket. This allows both buckets to be used for the serving of data, which
may provide faster data-access for users and applications in remote
geographies.

Note, however, that XDCR provides only a single basic mechanism from which
replications are built: this is the _unidirectional_ replication.
A _bidirectional_ topology
is created by implementing two _unidirectional_ replications: one from
source to target, the other from target to source.

Unidirectional and bidirectional replication can be used to create
complex topologies; an example being the _ring_ topology, where
multiple clusters each connect to exactly two peers, so that a complete
ring of connections is formed.

Alternatively, multiple clusters might
use XDCR to maintain a consistent view of the same data, represented as
an individual, replicated bucket on each cluster.

Note that when a bucket is specified as the source for an XDCR replication,
_all_ data in the bucket is replicated. Thus, if replication is
configured between source and target buckets that initially contain
different data-sets, the replication-process places the
superset on each bucket.

[#xdcr-conflict-resolution]
== XDCR Conflict Resolution

In some cases, especially when bidirectionally replicated data is being
modified by applications in different locations, _conflicts_ may arise:
meaning that the data of one or more documents has been differently
modified more or less simultaneously, requiring resolution.
XDCR provides options for
_conflict resolution_, based on either _revision ID_ or _timestamp_,
whereby conflicted data can be saved consistently on source and target.

[xdcr-based-data-recovery]
== XDCR-Based Data Recovery

In the event of data-loss, the *cbrecovery* tool can be used to restore data.
The tool accesses remotely replicated buckets, previously created with XDCR,
and copies appropriate subsets of their data back onto the original
source cluster.

By means of intra-cluster replication, Couchbase Server allows one or more
replicas to be created for each vBucket on
the cluster. This helps to ensure continued data-availability in the event of
node-failure.

However, if multiple nodes within a single cluster fail simultaneously, one or
more active vBuckets and all their replicas may be affected; meaning that lost
data cannot be recovered locally.

In such cases, provided that a bucket affected by such failure has already been
established as a source bucket for XDCR, the lost data may be retrieved from the
bucket defined on the remote server as the corresponding replication-target.
This retrieval is achieved from the command-line, by means of the Couchbase
*cbrecovery* tool.

[xdcr-security]
== XDCR Security

XDCR configuration requires that the administrator provide a
username and password appropriate for access to the target cluster. When
replication occurs, the password is automatically supplied, along with
the data.
By default, XDCR transmits both password and
data in non-secure form.
Optionally however, a secure connection can be enabled between clusters,
in order to
secure either password alone, or both password and data.

Note that if the password received by the destination cluster requires
authentication by an LDAP server, the destination cluster communicates with the
LDAP server in plain text, using `saslauthd`.
This is described in
xref:security:security-saslauthd-new.adoc[Setting Up saslauthd].

A secure XDCR connection is enabled either by SCRAM-SHA or by TLS â€” depending
on the administrator-specified connection-type, and the server-version of
the destination cluster.
Use of TLS involves certificate management: for information on preparing and
using certificates, see
xref:security:security-certs-auth.adoc[Certificate-Based Authentication].

Two administrator-specified connection-types are possible:

* _Half_ Secure: Secures the specified password
only: it does not secure data. The password is secured
by hashing with SCRAM-SHA, when the destination cluster is running
Couchbase Enterprise Server 5.5 or later; and by
TLS encryption, when the destination cluster is running a pre-5.5
Couchbase Enterprise Server. The root certificate of the destination cluster
must be provided, for a successful TLS connection to be achieved.
* _Full_ Secure: Handles both authentication and data-transfer via TLS.

For step-by-step procedures, see
xref:xdcr:xdcr-managing-security.adoc[XDCR Security]

[#xdcr-advanced-settings]
== XDCR Advanced Settings

The reliability and performance of XDCR can be fine-tuned by means
of configuration-settings, specified when a replication is defined.
These settings modify _compression_, source and target _nozzles_
(worker threads), _checkpoints_, _counts_, _sizes_, _network
usage limits_, and more.
